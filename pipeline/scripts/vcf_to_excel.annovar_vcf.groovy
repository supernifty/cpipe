// vim: shiftwidth=4:ts=4:expandtab:cindent:number
/////////////////////////////////////////////////////////////////////////////////
//
// This file is part of Cpipe.
// 
// Cpipe is free software: you can redistribute it and/or modify
// it under the terms of the GNU General Public License as published by
// the Free Software Foundation, under version 3 of the License, subject
// to additional terms compatible with the GNU General Public License version 3,
// specified in the LICENSE file that is part of the Cpipe distribution.
//
// Cpipe is distributed in the hope that it will be useful,
// but WITHOUT ANY WARRANTY; without even the implied warranty of 
// MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
// GNU General Public License for more details.
//
// You should have received a copy of the GNU General Public License
// along with Cpipe.  If not, see <http://www.gnu.org/licenses/>.
//
/////////////////////////////////////////////////////////////////////////////////
//
// VCF to Excel Format Conversion
//
// This script reads the VCF file generated by Annovar
// and produces 
// * an Excel file that can be easily viewed and filtered by less technical users.
// * a VCF file with additional annotations that can be imported into LOVD
//
// Requires: Groovy NGS Utils (https://github.com/ssadedin/groovy-ngs-utils)
//           ExcelCategory    (https://github.com/ssadedin/excelcatgory)
//
/////////////////////////////////////////////////////////////////////////

import groovy.sql.Sql
import com.xlson.groovycsv.*
import au.com.bytecode.opencsv.*
import org.apache.commons.cli.Option

// Parse command line args
CliBuilder cli = new CliBuilder(usage: "vcf_to_excel.annovar_vcf.groovy [options]\n")
cli.with {
  s 'comma separated list of samples to include', args:1, required:true
  a 'Annovar file containing annotations', args: Option.UNLIMITED_VALUES, required:true
  o 'Name of output file', args:1, required:true
  x 'Comma separated list of functional types to exclude', args:1
  si 'sample meta data file for the pipeline', args:1, required:true
  db 'Sqlite database containing known variants. If known, a column will be populated with the count of times observed.', args:1
  gc 'File listing genes and categories', args:1, required:true
  oocf 'Count at which out-of-cohort variants will cause variants to be filtered from report', args:1, required: true
  pgx 'VCF file containing variants to treat as pharmacogenomic variants (always report)', args:1
  bam 'BAM file for annotating coverage depth where not available from VCF files', args: Option.UNLIMITED_VALUES
  pgxcov 'Coverage threshold below which a pharmocogenomic site is considered untested (15)', args: 1
  annox 'Directory to send Annovar style per-sample summaries to', args: 1, required: true
  xprof 'Analysis profiles to exclude from contributing variant counts in variant filtering by internal database', args:1
  log 'Log file for writing information about variants filtered out', args: 1
}
opts = cli.parse(args)

// Quick and simple way to exit with a message
err = { msg ->
  System.err.println("\nERROR: " + msg + "\n")
  cli.usage()
  System.err.println()
  System.exit(1)
}

if(!opts) {
   cli.usage()
   err "Failed to parse command line options"
}
args = opts.arguments()

Writer log = new File(opts.log?:'/dev/null').newWriter()
msg = { m ->
  System.err.println( new Date().toString() + "\t" + m )
  log.println( m )
}

int out_of_cohort_variant_count_threshold = opts.oocf.toInteger() 

def pg_variants = []
if(opts.pgx) { 
    pg_variants = VCF.parse(opts.pgx)
}

int pgx_coverage_threshold = opts.pgxcov ? opts.pgxcov.toInteger() : 15

sample_info = SampleInfo.parse_sample_info(opts.si)
msg( "INFO: sample_info ${sample_info}" )

exclude_types = opts.x ? opts.x.split(",") : []
excluded_profiles_from_counts = opts.xprof ? opts.xprof.split(",") as List : ["AML"]

samples = opts.s.split(",")

Map<String,SAM> bams = null
if(opts.bams) {
    bams = opts.bams.collectEntries { def bam = new SAM(it); [ bam.samples[0], bam ] }
    msg "="*80
    msg "Read ${bams.size()} BAM files for querying read depth:"
    bams.each {  msg "Sample: $it.key => $it.value.samFile " }
    msg "="*80
}

// determine incoming fields
first_vcf = VCF.parse( opts.as[0] )
VCF_INFO_FIELDS = first_vcf.headerLines.grep {
    String hline -> hline.startsWith( '##INFO' )
}.collect {
    first_vcf.parseInfoMetaData( it )['ID']
}

msg "Input fields are " + VCF_INFO_FIELDS

// Read all the annovar files
msg "Processing ${opts.as.size()} incoming VCF files"

// connect to database, if specified
db = null
if(opts.db) { 
    db = new VariantDB(opts.db)
}

// Read the gene categories
geneCategories = new File(opts.gc).readLines()*.split('\t').collect { [it[0],it[1]] }.collectEntries()

// input fields
AACHANGE_FIELDS = VCF_INFO_FIELDS.grep { it.startsWith("AAChange") }
EXAC_FIELDS=["exac03","ExAC_ALL","ExAC_Freq"]

EXAC_FIELD = EXAC_FIELDS.find { it in VCF_INFO_FIELDS }
if(EXAC_FIELD == null) 
    EXAC_FIELD = "exac03"

ONEKG_FIELD="1000g2014oct_all"

ESP_FIELD = VCF_INFO_FIELDS.find { it =~ /^esp/ }
if(ESP_FIELD == null)
    ESP_FIELD = "esp5400_all"

LJB_FIELDS = [ "SIFT_score", "SIFT_pred", "Polyphen2_HVAR_score", "Polyphen2_HVAR_pred", "LRT_score", "LRT_pred", "MutationTaster_score", "MutationTaster_pred", "GERP++_RS", "phyloP100way_vertebrate"]

// The LJB fields changed column headings. To preserve backwards compatibility with
// downstream scripts, we replace them with the old headings in output
OLD_LJB_FIELDS = [ "LJB_SIFT", "LJB_SIFT_Pred", "LJB_PolyPhen2", "LJB_PolyPhen2_Pred", "LJB_LRT", "LJB_LRT_Pred", "LJB_MutationTaster", "LJB_MutationTaster_Pred", "LJB_GERP++", "LJB_PhyloP"]

// Order preferred if clinicians need to review output directly
OUTPUT_FIELDS = ["Func", "Gene", "ExonicFunc"] + 
                AACHANGE_FIELDS + 
                ["Gene Category", "Priority_Index", "CADD_raw", "CADD_phred", "Condel", "phastConsElements46way", ESP_FIELD, ONEKG_FIELD, "snp138", EXAC_FIELD] +
                LJB_FIELDS + 
                [ "genomicSuperDups", "Chr", "Start", "End", "Ref", "Alt", "Otherinfo", "Qual", "Depth", "#Obs", "RefCount", "AltCount"] // TODO removed priority_tx

CENTERED_COLUMNS = ["Gene Category", "Priority_Index", ONEKG_FIELD, ESP_FIELD, "LJB_PhyloP_Pred","LJB_SIFT_Pred","LJB_PolyPhen2","LJB_PolyPhen2_Pred"]

// The output headings are sometimes different to the input headings
// this is done to preserve compatibility as annovar headings change
// occasionally with the software
HEADING_MAP = OUTPUT_FIELDS.collectEntries{[it,it]} + [
   "phastConsElements46way" : "Conserved",
   "esp5400_All" : "ESP5400_ALL",
   "1000g2010nov_all"  : "1000g2010nov_ALL",
   ONEKG_FIELD  : "1000g",
   "snp138" : "dbSNP138",
   "genomicSuperDups" : "SegDup",
   "ExAC_ALL" : "exac03",
   "ExAC_Freq" : "exac03",
   "CADD_raw": "CADD"
] + [ LJB_FIELDS, OLD_LJB_FIELDS ].transpose().collectEntries()

// if gene contains a (, return what's contained in () else return aaChange
//
extractAAChange = { gene, aaChange ->
    if(gene.indexOf("(")>=0) {
        def geneParts = (gene =~ /(.*)\((.*)\)/)[0]
        gene = geneParts[1].toString()
        return geneParts[2].toString()
    }
    else {
        return aaChange
    }
}

//
// Utility function to collect information about a variant into the columns
// required for export.
//
collectOutputValues = { lineIndex, funcGene, variant, sample, variant_counts ->

    // Build up values for the row in a map with the column name as the key
    def outputValues = [:]

    (func,gene) = funcGene

    for(aaChange in AACHANGE_FIELDS) {
        outputValues[aaChange] = extractAAChange(gene, variant.info[aaChange])
    }
    outputValues.ExonicFunc = func == "splicing" ? "" : variant.info.ExonicFunc

    // copy annovar fields to output row
    for(af in VCF_INFO_FIELDS) {
        if(variant.info.containsKey(af)) {
            // undo annovar character replacements
            outputValues[af] = variant.info[af].toString().replaceAll('_', ' ').replaceAll( "\\\\x3b", ";" ).replaceAll( "\\\\x3e", "=" )
        }
    }

    // New version of Annovar puts het/hom, Qual and Depth all in one tab separated field called Otherinfo
    // def otherInfo = variant.info.Otherinfo.split("\t")
    outputValues["Otherinfo"] = (variant.dosages[0] == 1 ? "het" : "hom")
    variant.update{ variant.info.DosageInfo = (variant.dosages[0] == 1 ? "het" : "hom") }

    def geneCategory = geneCategories[gene]
    if(sample_info[sample].geneCategories[gene]) {
        geneCategory = sample_info[sample].geneCategories[gene]
    }

    outputValues["Gene Category"] = geneCategory ?: 1
    variant.update { variant.info.GeneCategory = geneCategory ?: 1 } // default to 1

    outputValues["Gene"] = gene
    outputValues["Func"] = func

    outputValues["Qual"] = variant.qual
    outputValues["Depth"] = variant.info.DP
    outputValues["Priority_Index"] = variant.info.Priority
    outputValues["Chr"] = variant.chr
    outputValues["Start"] = variant.pos
    outputValues["End"] = variant.pos + variant.size() // was Start, End
    outputValues["Ref"] = variant.ref
    outputValues["Alt"] = variant.alt
    if (variant.info.containsKey("CSQ")) {
      csq0 = variant.info["CSQ"].split( ",", -1 )[0]
      csq = csq0.split("\\|", -1)
      if ( csq.length > 28 ) {
         condel = csq[28]
         outputValues["Condel"] = condel
      }
    }

    outputValues.CADD = variant.info.CADD_raw != null ? variant.info.CADD_raw : ""

    if(db) {
        outputValues["#Obs"] = variant_counts.in_target
    }

    outputValues.RefCount = outputValues.AltCount = "";
    if(!variant) { 
        msg("WARNING: no variant specified")
        return outputValues // Cannot annotate allele depths for this variant
    }

    // Try to annotate allele frequencies
    def gt = variant.sampleGenoType(sample)
    if(gt) {
        // Reference depth
        if (gt.containsKey('AD')) {
            outputValues.RefCount = gt.AD[0]

            // Alternate depth depends on which allele
            int altAllele = 1 // (variant.alts.size()==1)?1:variant.equalsAnnovar(variant.Chr, variant.Start.toInteger(), variant.Alt)
            outputValues.AltCount = gt.AD[altAllele]
        }
        else {
          msg("WARNING: variant $variant.chr:$variant.pos ($variant.ref/$variant.alt) had no AD info for sample $sample at line $lineIndex")
        }
    }
    else {
      msg("WARNING: variant $variant.chr:$variant.pos ($variant.ref/$variant.alt) had no genotype for sample $sample at line $lineIndex")
    }
    return outputValues
} // collectOutputValues 

// Because excel can only handle up to 30 chars in the worksheet name,
// we may have to shorten them
int sampleNumber = 1
MAX_SAMPLE_NAME_LENGTH=30
sheet_samples = [samples, samples.collect { 
    it.size() > MAX_SAMPLE_NAME_LENGTH ? "S_" + (sampleNumber++) + "_" + it.substring(0,MAX_SAMPLE_NAME_LENGTH-10) : it 
}].transpose().collectEntries()

//
// Build the spreadsheet and export CSV in the same loop
//
try {
    new ExcelBuilder().build {

        for(sample in samples) { // one sample per spreadsheet tab
            def s = sheet(sheet_samples[sample]) { 
                lineIndex = 0
                sampleCount = 0
                includeCount=0

                // Read the VCF file and sort the annovar output by Priority Index
                String samplePrefix = sample + "."
                String annovarName = opts.as.find{new File(it).name.startsWith(samplePrefix)}
                if(annovarName == null) {
                    err "The following samples did not have an associated VCF: $sample in Annovar files:\n${opts.as.join('\n')}"
                }

                msg "INFO: Processing $annovarName..."
                def annovar_vcf = VCF.parse( annovarName ) // TODO .sort{ -it.info.Priority }
                msg "INFO: Processing $annovarName: got ${annovar_vcf.getSize()} items"

                // add sample metadata
                for ( name in [ 'target', 'sampleType', 'geneCategories', 'batch', 'pedigree', 'sex' ,'consanguinity', 'ethnicity', 'dnaDates', 'captureDates', 'sequencingDates', 'dnaConcentrationNg', 'dnaQuality', 'dnaQuantity', 'meanCoverage', 'variantsFile', 'machineIds', 'sequencingContact', 'analysisContact', 'institution' ] ) {
                  if ( sample_info[sample][name] ) {
                    msg( "##metadata_$name=${sample_info[sample][name]}" )
                    annovar_vcf.headerLines.add( 1, "##metadata_$name=${sample_info[sample][name]}" )
                  }
                }
                // add new fields to info
                annovar_vcf.addInfoHeader( "Observations", "Number of times this variant was observed in out of cohort targets", new Integer(0) )
                annovar_vcf.addInfoHeader( "Filter", "Whether the variation should be filtered (allow|excluded-type|observation-count|dosage-zero)", new String("") )
                annovar_vcf.addInfoHeader( "GeneCategory", "An integer index assigned to a gene to indicate the strength of evidence of its association to a particular disease", new Integer(0) )
                annovar_vcf.addInfoHeader( "Purpose", "Whether the variant is diagnostic or pharmacogenomic (diag|phx)", new String("") )
                annovar_vcf.addInfoHeader( "DosageInfo", "Type of variant (het|hom)", new String("") )
                annovar_vcf.addInfoHeader( "VariantStatus", "(Untested|Absent|Present)", new String("") )

                // Write out header row
                bold { row {
                        cells(OUTPUT_FIELDS.collect {HEADING_MAP[it]} )
                } }

                msg "INFO: Priority genes for $sample are ${sample_info[sample].geneCategories.keySet()}"

                // We are going to write out a CSV that is identical to the original annovar output
                // but which includes our custom fields on the end
                // Start by writing the headers
                for(Variant av in annovar_vcf) { // each variant in the sample vcf
                    ++lineIndex
                    // if(lineIndex%5000==0)
                    msg "INFO: Processing variant $lineIndex..."
                    av.update{ av.info.Purpose = 'diag' }
                    av.update{ av.info.VariantStatus = 'Present' }

                    // note: check for exonic, because splice events show up as synonymous but with 
                    // Func="exonic;splicing", and should not be filtered out this way
                    if(av.info.ExonicFunc in exclude_types && av.info.Func=="exonic") { 
                        msg "INFO: Variant $av.chr:$av.pos excluded by being an excluded type: $av.info.ExonicFunc"
                        av.update { av.info.Filter = 'excluded-type' }
                        continue
                    }

                    if(av.sampleDosage(sample, 0)==0) { //if(av.sampleDosage(sample, av.alleles)==0)
                        msg "INFO: Variant $av.chr:$av.pos excluded by dosage zero"
                        av.update { av.info.Filter = 'dosage-zero' }
                        continue
                    }
                    av.update{ av.info.Otherinfo = (av.dosages[0] == 1 ? "het" : "hom") }
                    Map variant_counts = [total: 0, other_target:0]
                    if(db) {
                        variant_counts = db.queryVariantCounts(av, // variant
                                                               av.getAlleles()[0], // allele (was av.Alleles) TODO ok?
                                                               sample, // sampleId
                                                               sample_info[sample].target, // cohort
                                                               excludeCohorts: excluded_profiles_from_counts,
                                                               batch: sample_info[sample].batch)
                        av.update{ av.info.Observations = variant_counts.other_target }
                        if(variant_counts.other_target > out_of_cohort_variant_count_threshold) {
                            msg "INFO: Variant $av excluded by presence ${variant_counts.other_target} times in other targets"
                            av.update{ av.info.Filter = 'observation-count' }
                            continue
                        }
                    }
                    ++includeCount
                    ++sampleCount

                    def funcs = av.info.Func.split("\\\\x3b")
                    def genes = av.info.Gene.split("\\\\x3b")

                    [funcs,genes].transpose().each { funcGene ->
                        
                        def outputValues = collectOutputValues(lineIndex, funcGene, av, sample, variant_counts)

                        // Write the row into the spreadsheet
                        row {
                            OUTPUT_FIELDS.each { fieldName ->
                                if(fieldName in CENTERED_COLUMNS) { 
                                    center {cell(outputValues[fieldName])}
                                }
                                else {
                                    cell(outputValues[fieldName]) 
                                }
                            } // each
                        } // row
                  } // transpose.each
                  av.update{ av.info.Filter = 'allow' }
                  msg "INFO: Processed $lineIndex variants: done"
                } // end foreach Annovar variant

                // Now add pharmacogenomic variants
                def annovar_vcf_index = new VCFIndex( annovarName )
                for(pvx in pg_variants) {

                    values = OUTPUT_FIELDS.collect { "" }

                    // Check if the unfiltered VCF has the variant
                    // Note: there's an issue here about canonicalizing the variant
                    // representation. For now, it's being ignored.
                    def vx = annovar_vcf_index.contains(pvx)

                    List<Map> vepInfos = pvx.vepInfo
                    def genes = vepInfos*.SYMBOL.grep { it != null }.join(",")

                    def state = "Untested"
                    int depth = bams[sample].coverage(pvx.chr, pvx.pos)
                    // println "Queried depth $depth at $pvx.chr:$pvx.pos"
                    // TODO: why is vx sometimes null? should always be genotyped
                    if(vx && depth >= pgx_coverage_threshold) {
                        int allele = vx.findAlleleIndex(pvx.alleles[0])
                        state = vx.sampleDosage(sample, allele) > 0 ? "Present" : "Absent"
                    }
                    else { // Variant not called - but is there coverage?
                        if(depth >= pgx_coverage_threshold)
                            state = "Absent"
                        msg "WARNING : PGX variant $pvx was not genotyped for sample $sample"
                    }

                    // Convert to annovar form since we are using Annovar annotations in the 
                    // rest of the report
                    def annovarVx = vx ? vx.toAnnovar() : pvx.toAnnovar()

                    // Now set the fields that we can
                    def output = [ 
                        'Gene Category': 1, 
                        'Priority Index': 1, 
                        Func: "pharma", 
                        ExonicFunc: state,
                        Gene: genes,
                        snp138: pvx.id,
                        Chr: pvx.chr,
                        Start: pvx.pos,
                        End: pvx.pos + pvx.size(),
                        Ref: annovarVx.ref,
                        Obs: annovarVx.obs,
                        Otherinfo: vx ? (vx.dosages[0] == 1 ? "het" : "hom") : ""
                    ]
                    output.each { k, v ->
                        values[OUTPUT_FIELDS.indexOf(k)] = v 
                    }

                    csv_out = []
                    nvlcell = { cell(it == null ? "" : it ) }
                    row { 
                        OUTPUT_FIELDS.each { fieldName ->
                            if(fieldName in CENTERED_COLUMNS) { 
                                center { nvlcell(output[fieldName]) } 
                            }
                            else
                            if(fieldName == "ExonicFunc" && state == 'Present') {
                                red {nvlcell(output[fieldName])}  
                            }
                            else {
                                nvlcell(output[fieldName]) 
                            }
                        }
                    }
                    // add to variants
                    pvx.update{ pvx.info["VariantStatus"] = state }
                    pvx.update{ pvx.info["Purpose"] = "phx" }
                    annovar_vcf.add( pvx )
                }

                // write out modified variant list
                target_vcf_filename = "${opts.annox}/${sample}.annovarx.vcf"
                annovar_vcf.print( new PrintStream( new File( target_vcf_filename ) ) )
                msg "INFO: Wrote ${target_vcf_filename}"

            } // sheet sample
            msg "INFO: Sample $sample has ${sampleCount} / ${includeCount} of included variants"
            try { 
                s/*.autoFilter("A:"+(char)(65+6+samples.size()))*/.autoSize() 
            } 
            catch(e) { 
                msg "WARNING: Unable to autosize columns: " + String.valueOf(e) 
            }
            s.setColumnWidth(OUTPUT_FIELDS.indexOf("Gene"),60*256) // 30 chars wide for Gene column
            AACHANGE_FIELDS.each { aaChange -> 
                s.setColumnWidth(OUTPUT_FIELDS.indexOf(aaChange),30*256) // 60 chars wide for AAChange column
            }
            // s.setColumnWidth(OUTPUT_FIELDS.indexOf("AAChange_RefSeq"),30*256) // 60 chars wide for AAChange column
            // s.setColumnWidth(OUTPUT_FIELDS.indexOf("AAChange_UCSC"),30*256) // 60 chars wide for AAChange column
            s.setColumnWidth(OUTPUT_FIELDS.indexOf("Gene Category"),14*256) // 14 chars wide for Gene category column
        } // for(sample in samples) 

        sheet("README") {
            row { }
            row { cell("This sheet contains explanations of columns in the previous sheet(s)") }
            row {}
            row { cell("Gene").bold(); cell("The gene affected. A mutation may occur on multiple rows if more than one gene or transcript is affected") }
            row { cell("ESP5400").bold(); cell("Frequency of allele in ESP project (5400 exomes)") }
            row { cell("1000g2010nov_all").bold(); cell("Frequency of allele in 1000 Genomes project 2010 Nov release") }
            row { cell("LJB_XXX").bold(); cell("DBNSFP annotations indicating predictions of pathogenicity") }
            row { cell(""); cell("Numeric: 0 = low impact, 1.0 = high impact") }
            row { cell(""); cell("D=Damaging") }
            row { cell(""); cell("P=Probably Damaging") }
            row { cell(""); cell("T=Tolerated") }
            row { cell(""); cell("N=Neutral") }
            row { cell(""); cell("B=Benign") }
            row { cell(""); cell("See link below for more information") }
            row { cell(""); cell("http://dbnsfp.houstonbioinformatics.org/dbNSFPzip/dbNSFP2.0b4.readme.txt").link("http://dbnsfp.houstonbioinformatics.org/dbNSFPzip/dbNSFP2.0b4.readme.txt") }
            row {}
            if(opts.x) {
                    row{ cell("NOTE:").bold(); cell("The following categories of variant are excluded from this spreadsheet:")}
                    row{ cell(""); cell( opts.x ) }
            }
        }.autoSize()
    }.save(opts.o)
}
finally {
    if (db) {
       db.close()
    }
    log.close()
}
